{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import torch, torchvision\n",
    "print(torch.__version__, torch.cuda.is_available())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "\n",
    "# import some common libraries\n",
    "import numpy as np\n",
    "import os, json, cv2, random\n",
    "from PIL import Image\n",
    "from matplotlib.pyplot import imshow\n",
    "import json\n",
    "\n",
    "#import some common detectron2 utilities\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
    "from detectron2.data.datasets import register_coco_instances\n",
    "\n",
    "print(\"finish importing\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Prepare Data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "'''\n",
    "The file structure of the dataset\n",
    "coco (DATA_ROOT)\n",
    "    L modified_train2017.json\n",
    "    L modified_val2017.json\n",
    "    L image/\n",
    "'''\n",
    "DATA_ROOT = './coco'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "register_coco_instances(\n",
    "    \"modify_coco_train\", \n",
    "    {}, \n",
    "    os.path.join( DATA_ROOT, \"modified_train2017.json\"), \n",
    "    os.path.join( DATA_ROOT, \"image\")\n",
    ")\n",
    "#register_coco_instances(\"modify_coco_val\"  , {}, f\"{DATA_ROOT}/jmodified_val2017.json\"  , f\"{DATA_ROOT}/image\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "with open('./modified_category.json', 'r') as f:\n",
    "    NUM_CLASSES = len(json.load(f))\n",
    "print(f\"NUM_CLASSES = {NUM_CLASSES}\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Prepare for Training"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from detectron2.engine import DefaultTrainer\n",
    "\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file( model_zoo.get_config_file(  \"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")\n",
    "\"\"\"\n",
    "Model Zoo Link: \n",
    "https://github.com/facebookresearch/detectron2/blob/master/\n",
    "MODEL_ZOO.md#coco-instance-segmentation-baselines-with-mask-r-cnn\n",
    "\"\"\"\n",
    "cfg.DATASETS.TRAIN = (\"modify_coco_train\",)\n",
    "cfg.DATASETS.TEST  = ()\n",
    "# Detectron default 4\n",
    "cfg.DATALOADER.NUM_WORKERS = 4\n",
    "# Detectron default 40000\n",
    "cfg.SOLVER.MAX_ITER = 160_000\n",
    "'''\n",
    "Detectron default \n",
    "Base Learning rate 0.001\n",
    "GAMMA              0.1 \n",
    "STEP               (30_000,)\n",
    "WEIGHT DECAY       0.000_1\n",
    "MOMENTUM           0.9\n",
    "    GAMMA : Learning rate decay factor\n",
    "    STEPS: num of iter for learning rate decay by gamma\n",
    "   \n",
    "MASK RCNN PAPER : https://arxiv.org/pdf/1703.06870.pdf\n",
    "    Base LR 0.02\n",
    "    decay by 10 @ 120k/160k\n",
    "    weight decay 0.000_1\n",
    "    momentum 0.9\n",
    "    \n",
    "    Cityscapes finetuning \n",
    "        Base LR 0.001\n",
    "        decay by 10 @ 18k/24k\n",
    "    \n",
    "    update baseline\n",
    "        Base LR 0.001\n",
    "        decay by 10 @ 120k,160k/180k\n",
    "    \n",
    "    Benefit form deeper model\n",
    "'''   \n",
    "cfg.SOLVER.BASE_LR      = 0.001  \n",
    "cfg.SOLVER.GAMMA        = 0.1 \n",
    "cfg.SOLVER.STEPS        = (120_000,)\n",
    "cfg.SOLVER.WEIGHT_DECAY = 0.000_1\n",
    "cfg.SOLVER.MOMENTUM     = 0.9\n",
    "\n",
    "#   ROI_HEADS.BATCH_SIZE_PER_IMAGE * SOLVER.IMS_PER_BATCH\n",
    "#   E.g., a common configuration is: 512 * 16 = 8192\n",
    "# Detectron default 16\n",
    "cfg.SOLVER.IMS_PER_BATCH = 32\n",
    "# Detectron default 512\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 2048\n",
    "\n",
    "# Number of classes \n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = NUM_CLASSES \n",
    "\n",
    "# Confident Level\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.7   # set a custom testing threshold\n",
    "\n",
    "cfg.OUTPUT_DIR = './model'\n",
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "#cfg.dump()"
   ],
   "outputs": [],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "trainer = DefaultTrainer(cfg) \n",
    "trainer.resume_or_load(resume=False)\n",
    "trainer.train()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Look at training curves in tensorboard:\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir output"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from detectron2.modeling import build_model\n",
    "from detectron2.checkpoint import DetectionCheckpointer\n",
    "final_model = build_model(cfg)\n",
    "\n",
    "checkpointer = DetectionCheckpointer(final_model, save_dir=\"model\")\n",
    "checkpointer.save(\"save_final_model\") \n",
    "\n",
    "# secondary save cfg as pickle\n",
    "import pickle\n",
    "with open('model_cfg.pickle' , 'wb') as f:\n",
    "    pickle.dump(cfg,f)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Check the Model on Robosuite Example "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "## load the model and the weight\n",
    "\"\"\"\n",
    "MODEL_ROOT\n",
    "    L model_cfg.pickle\n",
    "    L {cfg.OUTPUT_DIR}\n",
    "        L model_final.pth\n",
    "\"\"\"\n",
    "MODEL_ROOT = './'\n",
    "cfg = {}\n",
    "with open('model_cfg.pickle' , 'rb') as f:\n",
    "    cfg = pickle.load(f)\n",
    "\n",
    "print(cfg.OUTPUT_DIR)\n",
    "\n",
    "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")  # path to the model we just trained\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.7   # set a custom testing threshold\n",
    "predictor = DefaultPredictor(cfg)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "pic = np.asarray(Image.open('name_0.png'))\n",
    "imshow(pic)\n",
    "#pic = pic.transpose((2,0,1))\n",
    "print(pic.shape)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "outputs = predictor(pic)\n",
    "# look at the outputs. See https://detectron2.readthedocs.io/tutorials/models.html#model-output-format for specification\n",
    "print(outputs[\"instances\"].pred_classes)\n",
    "print(outputs[\"instances\"].pred_boxes)\n",
    "print(outputs['instances'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "# We can use `Visualizer` to draw the predictions on the image.\n",
    "v = Visualizer(pic[:, :, ::-1], MetadataCatalog.get(cfg.DATASETS.TRAIN[0]), scale=1)\n",
    "out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "imshow(out.get_image()[:, :, ::-1])\n",
    "im = Image.fromarray(out)\n",
    "out.save('output_name_0.jpg')"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'Visualizer' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-fc8e721ec321>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# We can use `Visualizer` to draw the predictions on the image.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVisualizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMetadataCatalog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDATASETS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw_instance_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"instances\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Visualizer' is not defined"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}